import re
from collections import Counter

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if type(text) is not str:
        raise TypeError
    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace('Ñ‘', 'Ðµ').replace('Ð', 'Ð•')
    text = re.sub(r'[\t\r\n\f\v]', ' ', text)
    return re.sub(r' +', ' ', text).strip()

def tokenize(text: str) -> list[str]:
    if type(text) is not str:
        raise TypeError
    return re.findall(r'\b[\w]+(?:-[\w]+)*\b', text)

def count_freq(tokens: list[str]) -> dict[str, int]:
    if type(tokens) is not list:
        raise TypeError
    return dict(Counter(tokens))

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    if type(freq) is not dict:
        raise TypeError
    return sorted(freq.items(), key=lambda x: (-x[1], x[0]))[:n]

print('normilize')
print(r'ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t  Out: ', normalize('ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t'))
print(r'Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°  Out: ', normalize('Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°', yo2e = True))
print(r'Hello\r\nWorld  Out: ', normalize('Hello\r\nWorld'))
print(r' Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹   Out: ', normalize(' Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ '))

print('tokenize')
print(r'Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€ Out:', tokenize('Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€'))
print(r'hello,world!!! Out:', tokenize('hello,world!!!'))
print(r'Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾ Out:', tokenize('Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾'))
print(r'2025 Ð³Ð¾Ð´ Out:', tokenize('2025 Ð³Ð¾Ð´'))
print(r'emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾ Out:', tokenize('emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾'))

print('count_freq & top_n')
freq1 = count_freq(["a","b","a","c","b","a"])
print(f'["a","b","a","c","b","a"], --> {freq1}, --> {top_n(freq1, 2)}')

freq2 = count_freq(["bb","aa","bb","aa","cc"])
print(f'["bb","aa","bb","aa","cc"], --> {freq2}, --> {top_n(freq2, 2)}')